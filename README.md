сохранение вэбстраниц из списка путей в csv все писалось под линух:
<h2>задача: </h2>
<p>было много файлов csv со списком вэб страниц </p>
<p>нужно было пройти по всему списку забрать пути и загрузить и сохранить старнички </p>
<p>при возможности сделать это быстро</p>
<h2>файлы: </h2>
<h3>reg_vk_sel.py</h3> 
<p>    запускает робота который использует драйвер firefox сохраняет так, как видит браузер</p>
<p>    работает медленно, сбоит если есть одинаковые имена файлов,</p>
<p>    надо следить, чоб в была папака 'out1' в корне с файлом</p>
<p>    невозможно пользоваться машиной, пока работает скрипт</p>
<h3>aiohttp_req_vk.py</h3> 
<p>    работает асинхронно шлет</p>
<p>    по 250 запросов // можно больше, но некоторые сайты отслеживают число запросов и режут ответ</p>
<p>    максимально  отправлял 1000 в связи с ограничением ОС по открытию файловых дискриптеров</p>
<p>    сохраняет только текст ответа без медиа</p>
<h3>req.py и req_1.py</h3> 
<p>    аналоги aiohttp_req_vk.py, только более медленные </p>
